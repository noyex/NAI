{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4f7bc412b663c966",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f7bc412b663c966",
        "outputId": "b42d2b85-6e6d-452a-fd84-e67896976b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (4.48.0)\n",
            "Requirement already satisfied: torch in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
            "Requirement already satisfied: langchain-community in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (0.3.15)\n",
            "Requirement already satisfied: youtube_transcript_api in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (0.6.3)\n",
            "Requirement already satisfied: filelock in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Python/3.9/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Python/3.9/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Python/3.9/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /Library/Python/3.9/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Python/3.9/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.31)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.1.147)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Library/Python/3.9/site-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Python/3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Python/3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Python/3.9/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Python/3.9/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Python/3.9/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Python/3.9/site-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: anyio in /Library/Python/3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Python/3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Python/3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Library/Python/3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mikolajszechniuk/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Library/Python/3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install  transformers torch langchain-community youtube_transcript_api"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ab1ffe0969f2cf",
      "metadata": {
        "id": "f0ab1ffe0969f2cf"
      },
      "source": [
        "# 1. RAG - Porozmawiaj z danymi\n",
        "Można użyć `document_loaders` z biblioteki `langchain-community` żeby załadować różne typy danych i \"porozmawiać z nimi\" używając LLMów.\n",
        "\n",
        "Biblioteka `langchain-community` oferuje wiele różnych loaderów, między innymi:\n",
        "- [Web](https://python.langchain.com/docs/integrations/document_loaders/web_base/)\n",
        "- [Twitter](https://python.langchain.com/docs/integrations/document_loaders/twitter/)\n",
        "- [Discord](https://python.langchain.com/docs/integrations/document_loaders/discord/)\n",
        "- [Github](https://python.langchain.com/docs/integrations/document_loaders/github/)\n",
        "- [CSV](https://python.langchain.com/docs/integrations/document_loaders/csv/)\n",
        "- [Youtube](https://python.langchain.com/docs/integrations/document_loaders/youtube_transcript/)\n",
        "\n",
        "i wiele więcej."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ab046b467f5f36",
      "metadata": {
        "id": "e9ab046b467f5f36"
      },
      "source": [
        "### Zaimportować Loader\n",
        "Na początek trzeba zaimportować odpowiedni moduł z `langchain_community.document_loaders`. [Tutaj](https://python.langchain.com/docs/integrations/document_loaders/) można znaleźć wszystkie dostępne opcje.\n",
        "\n",
        "Niektóre loadery wymagają dodatkowych dependencji które trzeba samodzielnie doinstalować."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1bc2797b90900050",
      "metadata": {
        "id": "1bc2797b90900050"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc660e5e921fa17",
      "metadata": {
        "id": "bcc660e5e921fa17"
      },
      "source": [
        "### Załadować dane\n",
        "Stworzyć loader i użyć metody `load` żeby załadować dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5b60d0175f129e92",
      "metadata": {
        "id": "5b60d0175f129e92"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(file_path=\"zaliczenie.pdf\")\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1bbdeb75b7e7ea",
      "metadata": {
        "id": "aa1bbdeb75b7e7ea"
      },
      "source": [
        "### Załadować Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e93717772620649",
      "metadata": {
        "id": "6e93717772620649"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a059d0b0da9a4c489c1c534ecbd1fbf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92333780a01442c3b674ecbaa864a8e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af40e618cc1e4472ba2a87f40df66e8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a316d57eeb2e4d8b9a929fb56c02073c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0341195f07a0416184c1ed8bcd764432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f5141e1a344e96862888bcffde1ac6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fee6f9d47a94da5934dc055c63fce8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline  # huggingface\n",
        "\n",
        "model_id = \"gpt2\"\n",
        "model = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4187e8ad67616e8f",
      "metadata": {
        "id": "4187e8ad67616e8f"
      },
      "source": [
        "### Zaimplementować funkcję `generate`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d72303c4625c2c3",
      "metadata": {
        "id": "5d72303c4625c2c3"
      },
      "outputs": [],
      "source": [
        "def generate(prompt: str) -> str:\n",
        "    response = model(prompt, max_new_tokens=100, temperature=0.7)\n",
        "    if response and isinstance(response, list) and \"generated_text\" in response[0]:\n",
        "        return response[0][\"generated_text\"]\n",
        "    else:\n",
        "        raise ValueError(\"Nie można odczytać wygenerowanego tekstu z odpowiedzi modelu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e58f7b5b2bf193fb",
      "metadata": {
        "id": "e58f7b5b2bf193fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Hello World!\\n\\nI have an old friend who is a good friend of mine, a man named Ben. He has been with me at the last minute and told me that he wanted to play the game with me. I told him he could play it with me but he had to do it the way it was programmed. When Ben came out of his bed he was so excited to play and so excited to play, he told me that he would make me a card with the word \"Haven\" in'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the `generate` function\n",
        "generate(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ed89b83521d067",
      "metadata": {
        "id": "e6ed89b83521d067"
      },
      "source": [
        "### Napisać prompt\n",
        "Napisać prompt bazowy na podstawie którego zostanie wygenerowana odpowiedź na `query` użytkownika w oparciu o dostępne dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "44af8a324d71cfe3",
      "metadata": {
        "id": "44af8a324d71cfe3"
      },
      "outputs": [],
      "source": [
        "BASE_PROMPT = \"\"\"\n",
        "You are an advanced assistant. Use the provided data to generate a precise and helpful response to the query below.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Data:\n",
        "{data}\n",
        "\n",
        "Your response should be clear, concise, and directly address the query based on the data provided.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565704527b83fbfc",
      "metadata": {
        "id": "565704527b83fbfc"
      },
      "source": [
        "### Wygenerować odpowiedź"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "10a95bf7967552bb",
      "metadata": {
        "id": "10a95bf7967552bb"
      },
      "outputs": [],
      "source": [
        "query = \"Summarize this project\"\n",
        "prompt = BASE_PROMPT.format(query=query, data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "338cc51237e17f58",
      "metadata": {
        "id": "338cc51237e17f58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4347 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "generate(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1086294c02679db3",
      "metadata": {
        "id": "1086294c02679db3"
      },
      "source": [
        "# 2. Prompt Chaining\n",
        "Można łączyć wiele promptów jeden po drugim, aby przeprowadzać transformacje lub dodatkowe procesy na generowanych odpowiedziach przed osiągnięciem  pożądanego rezultatu.\n",
        "\n",
        "Zadaniem będzie przekształcić zadanie programistyczne w gotowy fragment kodu, łącząc prompty w następujący łańcuch:\n",
        "1. Wygenerować plan rozwiązania problemu (najlepiej w krokach)\n",
        "2. Wygenerować dodatkowe kwestie, które należy wziąć pod uwagę\n",
        "3. Wygenerować ostateczny kod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37194ea74acf6c9e",
      "metadata": {
        "id": "37194ea74acf6c9e"
      },
      "source": [
        "### Zdefiniować prompty\n",
        "\n",
        "Prompt musi być odpowiednio sformatowany. Możesz użyć tagów HTML, markdown lub innych opcji formatowania.\n",
        "W zapytaniach należy używać placeholderów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa009b15a83954e3",
      "metadata": {
        "id": "fa009b15a83954e3"
      },
      "outputs": [],
      "source": [
        "GENERATE_PLAN_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholder for `query`.\n",
        "\n",
        "Make sure that this prompt generates a step-by-step plan to solve the problem, not the final code.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f668b97c8d07b74",
      "metadata": {
        "id": "2f668b97c8d07b74"
      },
      "outputs": [],
      "source": [
        "GENERATE_CONSIDERATIONS_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholder for `query` and `plan`.\n",
        "\n",
        "Make sure that this prompt generates additional considerations, not the final code or the new plan.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591be5ed093f2138",
      "metadata": {
        "id": "591be5ed093f2138"
      },
      "outputs": [],
      "source": [
        "GENERATE_CODE_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholders for `query`, `plan`, and `considerations`.\n",
        "\n",
        "Make sure that this prompt generates just the final code snippet without any additional information or comments from the model.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5fcd3fffe681bad",
      "metadata": {
        "id": "f5fcd3fffe681bad"
      },
      "source": [
        "### Stwórzyć łańcuch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e5c76bc5def6061",
      "metadata": {
        "id": "7e5c76bc5def6061"
      },
      "outputs": [],
      "source": [
        "def run_chain(query: str) -> str:\n",
        "    # 1. Generate a step-by-step plan\n",
        "    print(\"Generating a step-by-step plan...\")\n",
        "    prompt = GENERATE_PLAN_PROMPT.format(query=query)\n",
        "    plan = generate(prompt)\n",
        "    print(plan)\n",
        "\n",
        "    # 2. Generate additional considerations\n",
        "    print(\"\\n\\nGenerating additional considerations...\")\n",
        "    prompt = GENERATE_CONSIDERATIONS_PROMPT.format(query=query, plan=plan)\n",
        "    considerations = generate(prompt)\n",
        "    print(considerations)\n",
        "\n",
        "    # 3. Generate the final code snippet\n",
        "    print(\"\\n\\nGenerating the final code snippet...\")\n",
        "    prompt = GENERATE_CODE_PROMPT.format(query=query, plan=plan, considerations=considerations)\n",
        "    code = generate(prompt)\n",
        "    print(code)\n",
        "\n",
        "    return code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f721d89dfb13ec",
      "metadata": {
        "id": "33f721d89dfb13ec"
      },
      "source": [
        "### Przetestować łańcuch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b18ee8724e1d565",
      "metadata": {
        "id": "3b18ee8724e1d565"
      },
      "outputs": [],
      "source": [
        "example_query_1 = \"Write a Python function to find all prime numbers in a range from 1 to n.\"\n",
        "example_query_2 = \"Write a function that takes a list of words and a single word, and returns all the words in the list that are anagrams of the given word.\"\n",
        "example_query_3 = \"\"  # Add your own query to test the chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d86f3ee276f3d6f",
      "metadata": {
        "id": "9d86f3ee276f3d6f"
      },
      "outputs": [],
      "source": [
        "code_snippet = run_chain(example_query_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88ea156c8c2e92",
      "metadata": {
        "id": "c88ea156c8c2e92"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Code\n",
        "\n",
        "# Display the generated code snippet\n",
        "display(Code(code_snippet, language='python'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bccb365aae74e8",
      "metadata": {
        "id": "13bccb365aae74e8"
      },
      "source": [
        "Wkleić wygenerowany kod do komórki poniżej żeby sprawdzić czy działa poprawnie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221808d98ac6718b",
      "metadata": {
        "id": "221808d98ac6718b"
      },
      "outputs": [],
      "source": [
        "# Paste the generated code snippet here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "793f46a85e875dc",
      "metadata": {
        "id": "793f46a85e875dc"
      },
      "source": [
        "# 3. Walidator tekstu - Zadanie domowe\n",
        "Napisać walidator tekstu, który sprawdzi, czy tekst nie łamie żadnych reguł. Jeśli łamie, walidator powinien zwrócić odpowiednią informację."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8538ea274758ec26",
      "metadata": {
        "id": "8538ea274758ec26"
      },
      "source": [
        "### Zdefiniować kryteria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f40d35bae19b7b9",
      "metadata": {
        "id": "6f40d35bae19b7b9"
      },
      "outputs": [],
      "source": [
        "RULES = {\n",
        "    \"no_personal_info\": \"Should not contain any personal information.\",\n",
        "    \"english_only\": \"Should be in English.\",\n",
        "    \"no_questions\": \"Should not contain any questions.\",\n",
        "    # Feel free to add more rules here\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8e4e9ab64b9e0c",
      "metadata": {
        "id": "ba8e4e9ab64b9e0c"
      },
      "source": [
        "### Zaimplementować walidator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485771b1e16baa5e",
      "metadata": {
        "id": "485771b1e16baa5e"
      },
      "outputs": [],
      "source": [
        "VALIDATION_PROMPT = \"\"\"\n",
        "You are a validator. You need to ensure that the provided text meets the criteria.\n",
        "\n",
        "<Criteria>\n",
        "Code: {rule_code}\n",
        "Description: {rule_description}\n",
        "</Criteria>\n",
        "\n",
        "<Text to check>\n",
        "{text_to_check}\n",
        "</Text to check>\n",
        "\n",
        "# Output format\n",
        "Output the result in the following JSON format:\n",
        "{{\n",
        "    \"criteria_met\": bool,  # True if the criteria is met, False otherwise\n",
        "    \"feedback\": str  # Provide feedback if the criteria is not met, otherwise leave empty string\n",
        "}}\n",
        "\n",
        "Return just the JSON without any additional information or comments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3243dbb92461adc",
      "metadata": {
        "id": "b3243dbb92461adc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def validate_rule(text: str, rule_code: str) -> dict:\n",
        "    # 1. Load the rule description from the RULES dictionary for the given `rule_code`\n",
        "    # 2. Prepare the prompt using `VALIDATION_PROMPT` and `format` method\n",
        "    # 3. Run the `generate` function\n",
        "    # 4. Use `json.dumps` to transform the string output into a dictionary\n",
        "    # 5. Add the `rule_code` to the dictionary\n",
        "    # 6. Return the dictionary. The dictionary should contain the following keys: \"criteria_met\", \"feedback\", \"rule_code\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c53656e565680d",
      "metadata": {
        "id": "a0c53656e565680d"
      },
      "source": [
        "### Przetestować walidator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d46aedf6494843",
      "metadata": {
        "id": "92d46aedf6494843"
      },
      "outputs": [],
      "source": [
        "def run_validator(text: str):\n",
        "    for rule_code in RULES.keys():\n",
        "        print(f\"Checking rule '{rule_code}'...\")\n",
        "        result = validate_rule(text, rule_code)\n",
        "\n",
        "        assert result[\"criteria_met\"], f\"Rule '{rule_code}' is not met. Feedback: {result['feedback']}\"\n",
        "\n",
        "        print(\"Rule is met.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4bf4aac85fbf46",
      "metadata": {
        "id": "ec4bf4aac85fbf46"
      },
      "outputs": [],
      "source": [
        "text_to_check = \"My name is John and I like to play basketball. Do you know how to play basketball?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdd34918b854852",
      "metadata": {
        "id": "afdd34918b854852"
      },
      "outputs": [],
      "source": [
        "run_validator(text_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c722fd2a5e313312",
      "metadata": {
        "id": "c722fd2a5e313312"
      },
      "source": [
        "### Zaimplementować funkcję anonimizacji `anonymize` - Zadanie dodatkowe\n",
        "Jeśli tekst zawiera dane które łamią powyższe reguły (np. dane osobowe), funkcja `anonymize` ma podmienić te dane na placeholder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2574dbe5e53ed3",
      "metadata": {
        "id": "4b2574dbe5e53ed3"
      },
      "outputs": [],
      "source": [
        "ANONYMIZE_PROMPT = \"\"\"\n",
        "Your prompt here.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def anonymize(text: str) -> str:\n",
        "    # Implement the function that will replace the personal information with a placeholder\n",
        "    # Make sure to return the anonymized text (string)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66550d3d004de781",
      "metadata": {
        "id": "66550d3d004de781"
      },
      "outputs": [],
      "source": [
        "print(f\"Checking rule 'no_personal_info'...\")\n",
        "result = validate_rule(text_to_check, rule_code=\"no_personal_info\")\n",
        "\n",
        "if not result[\"criteria_met\"]:\n",
        "    print(\"Personal information found. Anonymizing the text...\")\n",
        "    anonymized_text = anonymize(text_to_check)\n",
        "    print(anonymized_text)\n",
        "\n",
        "    print(\"Re-running the validation...\")\n",
        "    validate_rule(anonymized_text, rule_code=\"no_personal_info\")\n",
        "\n",
        "    assert result[\"criteria_met\"], \"Anonymized text still contains personal information. Refine your prompt.\"\n",
        "\n",
        "print(\"Rule is met.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
