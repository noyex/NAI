{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4f7bc412b663c966",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f7bc412b663c966",
        "outputId": "b42d2b85-6e6d-452a-fd84-e67896976b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m2.4/2.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers torch langchain-community youtube_transcript_api"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ab1ffe0969f2cf",
      "metadata": {
        "id": "f0ab1ffe0969f2cf"
      },
      "source": [
        "# 1. Chat with the data\n",
        "You can use `document_loaders` from `langchain-community` to load different types of data sources and chat with them using LLMs.\n",
        "\n",
        "There are a lot of document loaders available in the `langchain-community` library, such as:\n",
        "- [Web](https://python.langchain.com/docs/integrations/document_loaders/web_base/)\n",
        "- [Twitter](https://python.langchain.com/docs/integrations/document_loaders/twitter/)\n",
        "- [Discord](https://python.langchain.com/docs/integrations/document_loaders/discord/)\n",
        "- [Github](https://python.langchain.com/docs/integrations/document_loaders/github/)\n",
        "- [CSV](https://python.langchain.com/docs/integrations/document_loaders/csv/)\n",
        "- [Youtube](https://python.langchain.com/docs/integrations/document_loaders/youtube_transcript/)\n",
        "\n",
        "and many more."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ab046b467f5f36",
      "metadata": {
        "id": "e9ab046b467f5f36"
      },
      "source": [
        "### Import the Loader\n",
        "First, you need to import the loader you want to use from `langchain_community.document_loaders`. You can find all the loaders [here](https://python.langchain.com/docs/integrations/document_loaders/).\n",
        "\n",
        "Note: some loaders require additional dependencies, so make sure to install them before using the loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc2797b90900050",
      "metadata": {
        "id": "1bc2797b90900050"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import YOUR_LOADER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc660e5e921fa17",
      "metadata": {
        "id": "bcc660e5e921fa17"
      },
      "source": [
        "### Load the Data\n",
        "Create a loader and use the `load` method of the loader to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b60d0175f129e92",
      "metadata": {
        "id": "5b60d0175f129e92"
      },
      "outputs": [],
      "source": [
        "loader = YOUR_LOADER() # Create your loader here\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1bbdeb75b7e7ea",
      "metadata": {
        "id": "aa1bbdeb75b7e7ea"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e93717772620649",
      "metadata": {
        "id": "6e93717772620649"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline  # huggingface\n",
        "\n",
        "model_id = \"\"  # Example unsloth/Llama-3.2-1B-Instruct\n",
        "model = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4187e8ad67616e8f",
      "metadata": {
        "id": "4187e8ad67616e8f"
      },
      "source": [
        "### Implement `generate` Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MeWF-OqP5WaC",
      "metadata": {
        "id": "MeWF-OqP5WaC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d72303c4625c2c3",
      "metadata": {
        "id": "5d72303c4625c2c3"
      },
      "outputs": [],
      "source": [
        "def generate(prompt: str) -> str:\n",
        "    # 1. Transform `input` into a desired format (e.g. it can be simply a string, or a list of dictionaries)\n",
        "    # The format of the input depends on the model you are using. You should check the model's documentation.\n",
        "    input = prompt\n",
        "\n",
        "    response = model(input, max_new_tokens=512)\n",
        "\n",
        "    # 2. Make sure to return just the content of the AI response (most of the time the model returns a dictionary with additional information)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58f7b5b2bf193fb",
      "metadata": {
        "id": "e58f7b5b2bf193fb"
      },
      "outputs": [],
      "source": [
        "# Test the `generate` function\n",
        "generate(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ed89b83521d067",
      "metadata": {
        "id": "e6ed89b83521d067"
      },
      "source": [
        "### Write a Prompt\n",
        "Write a base prompt that will generate an answer to the user query based on the provided data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44af8a324d71cfe3",
      "metadata": {
        "id": "44af8a324d71cfe3"
      },
      "outputs": [],
      "source": [
        "BASE_PROMPT = \"\"\"\n",
        "Your prompt here. Make sure to include the placeholders for `query` and `data`.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565704527b83fbfc",
      "metadata": {
        "id": "565704527b83fbfc"
      },
      "source": [
        "### Generate the Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a95bf7967552bb",
      "metadata": {
        "id": "10a95bf7967552bb"
      },
      "outputs": [],
      "source": [
        "query = \"Your query here. For example, 'What is the data about?'\"\n",
        "prompt = BASE_PROMPT.format(query=query, data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "338cc51237e17f58",
      "metadata": {
        "id": "338cc51237e17f58"
      },
      "outputs": [],
      "source": [
        "generate(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1086294c02679db3",
      "metadata": {
        "id": "1086294c02679db3"
      },
      "source": [
        "# 2. Prompt Chaining\n",
        "You can chain multiple prompts one after another to perform transformations or additional processes on the generated responses before reaching a final desired state.\n",
        "\n",
        "In this task we will try to convert a coding question into a code snippet. We will use the following chain:\n",
        "1. Generate a step-by-step plan to solve the problem.\n",
        "2. Generate additional considerations to take into account.\n",
        "3. Generate the final code snippet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37194ea74acf6c9e",
      "metadata": {
        "id": "37194ea74acf6c9e"
      },
      "source": [
        "### Define the Prompts\n",
        "\n",
        "Hints:\n",
        "- Make sure to structure the prompt. You can use HTML tags, markdown, or any other formatting options.\n",
        "- Use placeholders in the prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa009b15a83954e3",
      "metadata": {
        "id": "fa009b15a83954e3"
      },
      "outputs": [],
      "source": [
        "GENERATE_PLAN_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholder for `query`.\n",
        "\n",
        "Make sure that this prompt generates a step-by-step plan to solve the problem, not the final code.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f668b97c8d07b74",
      "metadata": {
        "id": "2f668b97c8d07b74"
      },
      "outputs": [],
      "source": [
        "GENERATE_CONSIDERATIONS_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholder for `query` and `plan`.\n",
        "\n",
        "Make sure that this prompt generates additional considerations, not the final code or the new plan.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591be5ed093f2138",
      "metadata": {
        "id": "591be5ed093f2138"
      },
      "outputs": [],
      "source": [
        "GENERATE_CODE_PROMPT = \"\"\"\n",
        "Your prompt here. Include the placeholders for `query`, `plan`, and `considerations`.\n",
        "\n",
        "Make sure that this prompt generates just the final code snippet without any additional information or comments from the model.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5fcd3fffe681bad",
      "metadata": {
        "id": "f5fcd3fffe681bad"
      },
      "source": [
        "### Create the Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e5c76bc5def6061",
      "metadata": {
        "id": "7e5c76bc5def6061"
      },
      "outputs": [],
      "source": [
        "def run_chain(query: str) -> str:\n",
        "    # 1. Generate a step-by-step plan\n",
        "    print(\"Generating a step-by-step plan...\")\n",
        "    prompt = GENERATE_PLAN_PROMPT.format(query=query)\n",
        "    plan = generate(prompt)\n",
        "    print(plan)\n",
        "\n",
        "    # 2. Generate additional considerations\n",
        "    print(\"\\n\\nGenerating additional considerations...\")\n",
        "    prompt = GENERATE_CONSIDERATIONS_PROMPT.format(query=query, plan=plan)\n",
        "    considerations = generate(prompt)\n",
        "    print(considerations)\n",
        "\n",
        "    # 3. Generate the final code snippet\n",
        "    print(\"\\n\\nGenerating the final code snippet...\")\n",
        "    prompt = GENERATE_CODE_PROMPT.format(query=query, plan=plan, considerations=considerations)\n",
        "    code = generate(prompt)\n",
        "    print(code)\n",
        "\n",
        "    return code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f721d89dfb13ec",
      "metadata": {
        "id": "33f721d89dfb13ec"
      },
      "source": [
        "### Test the Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b18ee8724e1d565",
      "metadata": {
        "id": "3b18ee8724e1d565"
      },
      "outputs": [],
      "source": [
        "example_query_1 = \"Write a Python function to find all prime numbers in a range from 1 to n.\"\n",
        "example_query_2 = \"Write a function that takes a list of words and a single word, and returns all the words in the list that are anagrams of the given word.\"\n",
        "example_query_3 = \"\"  # Add your own query to test the chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d86f3ee276f3d6f",
      "metadata": {
        "id": "9d86f3ee276f3d6f"
      },
      "outputs": [],
      "source": [
        "code_snippet = run_chain(example_query_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88ea156c8c2e92",
      "metadata": {
        "id": "c88ea156c8c2e92"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Code\n",
        "\n",
        "# Display the generated code snippet\n",
        "display(Code(code_snippet, language='python'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bccb365aae74e8",
      "metadata": {
        "id": "13bccb365aae74e8"
      },
      "source": [
        "You can copy-paste the generated code snippet and run it below to see if it works as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221808d98ac6718b",
      "metadata": {
        "id": "221808d98ac6718b"
      },
      "outputs": [],
      "source": [
        "# Paste the generated code snippet here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "793f46a85e875dc",
      "metadata": {
        "id": "793f46a85e875dc"
      },
      "source": [
        "# 3. Text Validator - Zadanie domowe\n",
        "Write a text validator that will check if the text is not breaking any criteria. If the text is not valid, the validator should provide feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8538ea274758ec26",
      "metadata": {
        "id": "8538ea274758ec26"
      },
      "source": [
        "### Define the Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f40d35bae19b7b9",
      "metadata": {
        "id": "6f40d35bae19b7b9"
      },
      "outputs": [],
      "source": [
        "RULES = {\n",
        "    \"no_personal_info\": \"Should not contain any personal information.\",\n",
        "    \"english_only\": \"Should be in English.\",\n",
        "    \"no_questions\": \"Should not contain any questions.\",\n",
        "    # Feel free to add more rules here\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8e4e9ab64b9e0c",
      "metadata": {
        "id": "ba8e4e9ab64b9e0c"
      },
      "source": [
        "### Implement the Validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485771b1e16baa5e",
      "metadata": {
        "id": "485771b1e16baa5e"
      },
      "outputs": [],
      "source": [
        "VALIDATION_PROMPT = \"\"\"\n",
        "You are a validator. You need to ensure that the provided text meets the criteria.\n",
        "\n",
        "<Criteria>\n",
        "Code: {rule_code}\n",
        "Description: {rule_description}\n",
        "</Criteria>\n",
        "\n",
        "<Text to check>\n",
        "{text_to_check}\n",
        "</Text to check>\n",
        "\n",
        "# Output format\n",
        "Output the result in the following JSON format:\n",
        "{{\n",
        "    \"criteria_met\": bool,  # True if the criteria is met, False otherwise\n",
        "    \"feedback\": str  # Provide feedback if the criteria is not met, otherwise leave empty string\n",
        "}}\n",
        "\n",
        "Return just the JSON without any additional information or comments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3243dbb92461adc",
      "metadata": {
        "id": "b3243dbb92461adc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def validate_rule(text: str, rule_code: str) -> dict:\n",
        "    # 1. Load the rule description from the RULES dictionary for the given `rule_code`\n",
        "    # 2. Prepare the prompt using `VALIDATION_PROMPT` and `format` method\n",
        "    # 3. Run the `generate` function\n",
        "    # 4. Use `json.dumps` to transform the string output into a dictionary\n",
        "    # 5. Add the `rule_code` to the dictionary\n",
        "    # 6. Return the dictionary. The dictionary should contain the following keys: \"criteria_met\", \"feedback\", \"rule_code\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c53656e565680d",
      "metadata": {
        "id": "a0c53656e565680d"
      },
      "source": [
        "### Test the Validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d46aedf6494843",
      "metadata": {
        "id": "92d46aedf6494843"
      },
      "outputs": [],
      "source": [
        "def run_validator(text: str):\n",
        "    for rule_code in RULES.keys():\n",
        "        print(f\"Checking rule '{rule_code}'...\")\n",
        "        result = validate_rule(text, rule_code)\n",
        "\n",
        "        assert result[\"criteria_met\"], f\"Rule '{rule_code}' is not met. Feedback: {result['feedback']}\"\n",
        "\n",
        "        print(\"Rule is met.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4bf4aac85fbf46",
      "metadata": {
        "id": "ec4bf4aac85fbf46"
      },
      "outputs": [],
      "source": [
        "text_to_check = \"My name is John and I like to play basketball. Do you know how to play basketball?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdd34918b854852",
      "metadata": {
        "id": "afdd34918b854852"
      },
      "outputs": [],
      "source": [
        "run_validator(text_to_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d591e51cf1dd185c",
      "metadata": {
        "id": "d591e51cf1dd185c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c722fd2a5e313312",
      "metadata": {
        "id": "c722fd2a5e313312"
      },
      "source": [
        "### Implement the `anonymize` Function - Zadanie dodatkowe\n",
        "If the text contains personal information, you can implement the `anonymize` function that will replace the personal information with a placeholder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2574dbe5e53ed3",
      "metadata": {
        "id": "4b2574dbe5e53ed3"
      },
      "outputs": [],
      "source": [
        "ANONYMIZE_PROMPT = \"\"\"\n",
        "Your prompt here.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def anonymize(text: str) -> str:\n",
        "    # Implement the function that will replace the personal information with a placeholder\n",
        "    # Make sure to return the anonymized text (string)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66550d3d004de781",
      "metadata": {
        "id": "66550d3d004de781"
      },
      "outputs": [],
      "source": [
        "print(f\"Checking rule 'no_personal_info'...\")\n",
        "result = validate_rule(text_to_check, rule_code=\"no_personal_info\")\n",
        "\n",
        "if not result[\"criteria_met\"]:\n",
        "    print(\"Personal information found. Anonymizing the text...\")\n",
        "    anonymized_text = anonymize(text_to_check)\n",
        "    print(anonymized_text)\n",
        "\n",
        "    print(\"Re-running the validation...\")\n",
        "    validate_rule(anonymized_text, rule_code=\"no_personal_info\")\n",
        "\n",
        "    assert result[\"criteria_met\"], \"Anonymized text still contains personal information. Refine your prompt.\"\n",
        "\n",
        "print(\"Rule is met.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
